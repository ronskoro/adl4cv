{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from plyfile import PlyData\n",
    "from glob import glob\n",
    "\n",
    "class ScanNet200Dataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.scans = self._load_scans()\n",
    "\n",
    "    def _load_scans(self):\n",
    "        scans = []\n",
    "        for scan_dir in os.listdir(self.root_dir): \n",
    "            scan_path = os.path.join(self.root_dir, scan_dir)\n",
    "            if os.path.isdir(scan_path):\n",
    "                ply_files = glob(os.path.join(scan_path, \"*.ply\"))\n",
    "                json_files = glob(os.path.join(scan_path, \"*.segs.json\"))\n",
    "                \n",
    "                if ply_files and json_files:\n",
    "                    ply_file = ply_files[0]\n",
    "                    json_file = json_files[0]\n",
    "                    scans.append((ply_file, json_file))\n",
    "                else:\n",
    "                    print(f\"Missing files in {scan_path}\")  # Debug print\n",
    "        return scans\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.scans)\n",
    "\n",
    "    def _load_ply(self, ply_file):\n",
    "        ply_data = PlyData.read(ply_file)\n",
    "        vertices = torch.tensor(ply_data['vertex'].data.tolist(), dtype=torch.float32)\n",
    "        return vertices\n",
    "\n",
    "    def _load_json(self, json_file):\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        segments = torch.tensor(data['segIndices'], dtype=torch.int64)\n",
    "        return segments\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ply_file, json_file = self.scans[idx]\n",
    "        vertices = self._load_ply(ply_file)\n",
    "        segments = self._load_json(json_file)\n",
    "        \n",
    "        sample = {'vertices': vertices, 'segments': segments}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom collate function to pad the sequence for resizing in the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))  # Remove None values\n",
    "    return {\n",
    "        'vertices': torch.nn.utils.rnn.pad_sequence([item['vertices'] for item in batch], batch_first=True),\n",
    "        'segments': torch.nn.utils.rnn.pad_sequence([item['segments'] for item in batch], batch_first=True)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1513\n"
     ]
    }
   ],
   "source": [
    "from path import Path\n",
    "\n",
    "path = Path(\"../data/scannet200/scans\") \n",
    "dataset = ScanNet200Dataset(root_dir=path)\n",
    "print(dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([211497, 7]) torch.Size([211497])\n",
      "torch.Size([138888, 7]) torch.Size([138888])\n",
      "torch.Size([89242, 7]) torch.Size([89242])\n",
      "torch.Size([49093, 7]) torch.Size([49093])\n",
      "torch.Size([206210, 7]) torch.Size([206210])\n",
      "torch.Size([182152, 7]) torch.Size([182152])\n",
      "torch.Size([120683, 7]) torch.Size([120683])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvertices\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msegments\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 47\u001b[0m, in \u001b[0;36mScanNet200Dataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     ply_file, json_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscans[idx]\n\u001b[0;32m---> 47\u001b[0m     vertices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_ply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mply_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     segments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_json(json_file)\n\u001b[1;32m     50\u001b[0m     sample \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertices\u001b[39m\u001b[38;5;124m'\u001b[39m: vertices, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegments\u001b[39m\u001b[38;5;124m'\u001b[39m: segments}\n",
      "Cell \u001b[0;32mIn[9], line 34\u001b[0m, in \u001b[0;36mScanNet200Dataset._load_ply\u001b[0;34m(self, ply_file)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_ply\u001b[39m(\u001b[38;5;28mself\u001b[39m, ply_file):\n\u001b[0;32m---> 34\u001b[0m     ply_data \u001b[38;5;241m=\u001b[39m \u001b[43mPlyData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mply_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     vertices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(ply_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertex\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mtolist(), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vertices\n",
      "File \u001b[0;32m~/anaconda3/envs/adl4cv/lib/python3.11/site-packages/plyfile.py:173\u001b[0m, in \u001b[0;36mPlyData.read\u001b[0;34m(stream, mmap, known_list_len)\u001b[0m\n\u001b[1;32m    171\u001b[0m             data_stream \u001b[38;5;241m=\u001b[39m stream\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m elt \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m--> 173\u001b[0m         \u001b[43melt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyte_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mknown_list_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknown_list_len\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43melt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m must_close:\n",
      "File \u001b[0;32m~/anaconda3/envs/adl4cv/lib/python3.11/site-packages/plyfile.py:525\u001b[0m, in \u001b[0;36mPlyElement._read\u001b[0;34m(self, stream, text, byte_order, mmap, known_list_len)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_mmap(stream, byte_order, known_list_len)\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;66;03m# A simple load is impossible.\u001b[39;00m\n\u001b[0;32m--> 525\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_bin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbyte_order\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_sanity()\n",
      "File \u001b[0;32m~/anaconda3/envs/adl4cv/lib/python3.11/site-packages/plyfile.py:667\u001b[0m, in \u001b[0;36mPlyElement._read_bin\u001b[0;34m(self, stream, byte_order)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prop \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperties:\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    666\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[prop\u001b[38;5;241m.\u001b[39mname][k] \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 667\u001b[0m             \u001b[43mprop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_bin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbyte_order\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    669\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PlyElementParseError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mearly end-of-file\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    670\u001b[0m                                    \u001b[38;5;28mself\u001b[39m, k, prop)\n",
      "File \u001b[0;32m~/anaconda3/envs/adl4cv/lib/python3.11/site-packages/plyfile.py:999\u001b[0m, in \u001b[0;36mPlyListProperty._read_bin\u001b[0;34m(self, stream, byte_order)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m--> 999\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43m_read_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_np\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_t\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m n:\n\u001b[1;32m   1001\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/adl4cv/lib/python3.11/site-packages/plyfile.py:1412\u001b[0m, in \u001b[0;36m_read_array\u001b[0;34m(stream, dtype, n)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;124;03mRead `n` elements of type `dtype` from an open stream.\u001b[39;00m\n\u001b[1;32m   1395\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;124;03m    If `n` elements could not be read.\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1412\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_np\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitemsize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _np\u001b[38;5;241m.\u001b[39mfrombuffer(stream\u001b[38;5;241m.\u001b[39mread(size), dtype)\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for data in dataset:\n",
    "    print(data['vertices'].shape, data['segments'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=1, collate_fn=custom_collate_fn)\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(batch['vertices'].shape, batch['segments'].shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adl4cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
